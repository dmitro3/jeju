/**
 * Managed Database Service
 *
 * Provides unified API for managing SQLit and PostgreSQL databases:
 * - Instance lifecycle management
 * - Connection pooling (PgBouncer for PostgreSQL)
 * - Automatic backups to IPFS/Arweave
 * - Read replicas for PostgreSQL
 * - Point-in-time recovery
 * - Metrics and monitoring
 */

import {
  getCurrentNetwork,
  getRpcUrl,
  tryGetContract,
} from '@jejunetwork/config'
import {
  type Address,
  createPublicClient,
  createWalletClient,
  type Hex,
  http,
  keccak256,
  stringToBytes,
} from 'viem'
import { privateKeyToAccount } from 'viem/accounts'
import { foundry } from 'viem/chains'
import { z } from 'zod'
import type { BackendManager } from '../storage/backends'

// ============================================================================
// Types
// ============================================================================

export type DatabaseEngine =
  | 'sqlit'
  | 'postgresql'
  | 'mysql'
  | 'redis'
  | 'mongodb'

export type DatabaseStatus =
  | 'pending'
  | 'provisioning'
  | 'running'
  | 'scaling'
  | 'backing_up'
  | 'restoring'
  | 'maintenance'
  | 'stopped'
  | 'failed'
  | 'terminated'

export type BackupStatus =
  | 'pending'
  | 'in_progress'
  | 'completed'
  | 'failed'
  | 'expired'

export type ReplicaRole = 'primary' | 'read_replica' | 'standby'

export interface DatabaseConfig {
  vcpus: number
  memoryMb: number
  storageMb: number
  readReplicas: number
  maxConnections: number
  connectionPoolSize: number
  backupRetentionDays: number
  pointInTimeRecovery: boolean
  encryptionAtRest: boolean
  encryptionInTransit: boolean
  publicAccess: boolean
  replicationFactor: number
  consistencyMode: 'strong' | 'eventual'
}

export interface DatabaseInstance {
  instanceId: Hex
  owner: Address
  engine: DatabaseEngine
  name: string
  status: DatabaseStatus
  config: DatabaseConfig
  connectionString: string
  createdAt: number
  updatedAt: number
  lastBackupAt: number
  planId: Hex
  region: string
}

export interface DatabasePlan {
  planId: Hex
  name: string
  engine: DatabaseEngine
  pricePerMonthWei: bigint
  limits: DatabaseConfig
  active: boolean
}

export interface Backup {
  backupId: Hex
  instanceId: Hex
  status: BackupStatus
  createdAt: number
  completedAt: number
  sizeBytes: number
  storageCid: string
  expiresAt: number
  isAutomatic: boolean
}

export interface Replica {
  replicaId: Hex
  instanceId: Hex
  role: ReplicaRole
  endpoint: string
  region: string
  lagMs: number
  healthy: boolean
}

export interface UsageMetrics {
  queriesExecuted: number
  rowsRead: number
  rowsWritten: number
  storageBytesUsed: number
  connectionCount: number
  cpuSecondsUsed: number
  lastUpdatedAt: number
}

export interface ConnectionPoolConfig {
  mode: 'transaction' | 'session' | 'statement'
  defaultPoolSize: number
  maxClientConnections: number
  reservePoolSize: number
  queryTimeout: number
  idleTimeout: number
}

export interface PostgresConnection {
  host: string
  port: number
  database: string
  user: string
  password: string
  ssl: boolean
  poolerEndpoint: string
  directEndpoint: string
}

export interface SQLitConnection {
  endpoint: string
  authToken: string
  syncUrl: string
  nodes: string[]
}

// ============================================================================
// Schemas
// ============================================================================

export const CreateDatabaseSchema = z.object({
  name: z
    .string()
    .min(1)
    .max(63)
    .regex(/^[a-z][a-z0-9-]*$/),
  engine: z.enum(['sqlit', 'postgresql', 'mysql', 'redis', 'mongodb']),
  planId: z.string(),
  region: z.string().default('us-east-1'),
  config: z
    .object({
      vcpus: z.number().min(1).max(64).optional(),
      memoryMb: z.number().min(512).max(524288).optional(),
      storageMb: z.number().min(1024).max(10485760).optional(),
      readReplicas: z.number().min(0).max(5).optional(),
      maxConnections: z.number().min(10).max(10000).optional(),
      connectionPoolSize: z.number().min(5).max(1000).optional(),
      backupRetentionDays: z.number().min(1).max(365).optional(),
      pointInTimeRecovery: z.boolean().optional(),
      publicAccess: z.boolean().optional(),
      replicationFactor: z.number().min(1).max(7).optional(),
      consistencyMode: z.enum(['strong', 'eventual']).optional(),
    })
    .optional(),
})

export const UpdateDatabaseSchema = z.object({
  vcpus: z.number().min(1).max(64).optional(),
  memoryMb: z.number().min(512).max(524288).optional(),
  storageMb: z.number().min(1024).max(10485760).optional(),
  readReplicas: z.number().min(0).max(5).optional(),
  maxConnections: z.number().min(10).max(10000).optional(),
  connectionPoolSize: z.number().min(5).max(1000).optional(),
})

// ============================================================================
// Connection Pool Manager (PgBouncer-like)
// ============================================================================

interface PooledConnection {
  id: string
  instanceId: string
  createdAt: number
  lastUsedAt: number
  inUse: boolean
  clientId: string | null
}

class ConnectionPoolManager {
  private pools = new Map<string, PooledConnection[]>()
  private configs = new Map<string, ConnectionPoolConfig>()
  private waitQueue = new Map<string, Array<(conn: PooledConnection) => void>>()

  configure(instanceId: string, config: ConnectionPoolConfig): void {
    this.configs.set(instanceId, config)
    this.pools.set(instanceId, [])
    this.waitQueue.set(instanceId, [])
  }

  async acquire(
    instanceId: string,
    clientId: string,
    timeoutMs = 5000,
  ): Promise<PooledConnection> {
    const pool = this.pools.get(instanceId)
    const config = this.configs.get(instanceId)

    if (!pool || !config) {
      throw new Error(`Pool not configured for instance: ${instanceId}`)
    }

    // Try to find an available connection
    const available = pool.find((c) => !c.inUse)
    if (available) {
      available.inUse = true
      available.lastUsedAt = Date.now()
      available.clientId = clientId
      return available
    }

    // Create new connection if under limit
    if (pool.length < config.defaultPoolSize) {
      const conn: PooledConnection = {
        id: crypto.randomUUID(),
        instanceId,
        createdAt: Date.now(),
        lastUsedAt: Date.now(),
        inUse: true,
        clientId,
      }
      pool.push(conn)
      return conn
    }

    // Wait for available connection
    return new Promise((resolve, reject) => {
      const timeout = setTimeout(() => {
        const queue = this.waitQueue.get(instanceId)
        if (queue) {
          const idx = queue.indexOf(resolve)
          if (idx >= 0) queue.splice(idx, 1)
        }
        reject(new Error('Connection pool timeout'))
      }, timeoutMs)

      this.waitQueue.get(instanceId)?.push((conn) => {
        clearTimeout(timeout)
        conn.inUse = true
        conn.lastUsedAt = Date.now()
        conn.clientId = clientId
        resolve(conn)
      })
    })
  }

  release(instanceId: string, connectionId: string): void {
    const pool = this.pools.get(instanceId)
    if (!pool) return

    const conn = pool.find((c) => c.id === connectionId)
    if (!conn) return

    conn.inUse = false
    conn.clientId = null
    conn.lastUsedAt = Date.now()

    // Check wait queue
    const queue = this.waitQueue.get(instanceId)
    if (queue && queue.length > 0) {
      const waiter = queue.shift()
      if (waiter) waiter(conn)
    }
  }

  getStats(instanceId: string): {
    total: number
    inUse: number
    available: number
    waiting: number
  } {
    const pool = this.pools.get(instanceId) ?? []
    const queue = this.waitQueue.get(instanceId) ?? []

    return {
      total: pool.length,
      inUse: pool.filter((c) => c.inUse).length,
      available: pool.filter((c) => !c.inUse).length,
      waiting: queue.length,
    }
  }

  cleanup(instanceId: string, maxIdleMs = 300000): void {
    const pool = this.pools.get(instanceId)
    const config = this.configs.get(instanceId)
    if (!pool || !config) return

    const now = Date.now()
    const minConnections = Math.min(5, config.defaultPoolSize)

    // Remove idle connections above minimum
    while (pool.length > minConnections) {
      const idleIdx = pool.findIndex(
        (c) => !c.inUse && now - c.lastUsedAt > maxIdleMs,
      )
      if (idleIdx < 0) break
      pool.splice(idleIdx, 1)
    }
  }

  destroy(instanceId: string): void {
    this.pools.delete(instanceId)
    this.configs.delete(instanceId)
    this.waitQueue.delete(instanceId)
  }
}

// ============================================================================
// Database Provisioner
// ============================================================================

interface ProvisioningJob {
  instanceId: string
  engine: DatabaseEngine
  config: DatabaseConfig
  region: string
  status: 'pending' | 'running' | 'completed' | 'failed'
  startedAt: number
  completedAt: number | null
  error: string | null
}

class DatabaseProvisioner {
  private jobs = new Map<string, ProvisioningJob>()

  async provision(
    instanceId: string,
    engine: DatabaseEngine,
    config: DatabaseConfig,
    region: string,
  ): Promise<{
    connectionString: string
    credentials: Record<string, string>
  }> {
    const job: ProvisioningJob = {
      instanceId,
      engine,
      config,
      region,
      status: 'running',
      startedAt: Date.now(),
      completedAt: null,
      error: null,
    }
    this.jobs.set(instanceId, job)

    console.log(
      `[DatabaseProvisioner] Starting provisioning for ${instanceId} (${engine})`,
    )

    if (engine === 'sqlit') {
      return this.provisionSQLit(instanceId, config, region)
    } else if (engine === 'postgresql') {
      return this.provisionPostgreSQL(instanceId, config, region)
    } else {
      throw new Error(`Unsupported engine: ${engine}`)
    }
  }

  private async provisionSQLit(
    instanceId: string,
    config: DatabaseConfig,
    region: string,
  ): Promise<{
    connectionString: string
    credentials: Record<string, string>
  }> {
    // Generate auth token
    const authToken =
      crypto.randomUUID().replace(/-/g, '') +
      crypto.randomUUID().replace(/-/g, '')

    // Determine node count based on replication factor
    const nodeCount = Math.max(3, config.replicationFactor)

    // In production, this would:
    // 1. Find available SQLit nodes in the region
    // 2. Initialize database cluster with replication
    // 3. Set up WAL shipping between nodes
    // 4. Configure consistency mode

    const nodes = Array.from(
      { length: nodeCount },
      (_, i) => `sqlit-${region}-${i}.dws.jejunetwork.org:4500`,
    )

    const endpoint = `https://sqlit-${instanceId}.dws.jejunetwork.org`
    const syncUrl = `wss://sqlit-${instanceId}.dws.jejunetwork.org/sync`

    const connectionString = `sqlit://${endpoint}?auth=${authToken}&consistency=${config.consistencyMode}`

    const job = this.jobs.get(instanceId)
    if (job) {
      job.status = 'completed'
      job.completedAt = Date.now()
    }

    console.log(
      `[DatabaseProvisioner] SQLit ${instanceId} provisioned with ${nodeCount} nodes`,
    )

    return {
      connectionString,
      credentials: {
        authToken,
        endpoint,
        syncUrl,
        nodes: nodes.join(','),
      },
    }
  }

  private async provisionPostgreSQL(
    instanceId: string,
    _config: DatabaseConfig,
    _region: string,
  ): Promise<{
    connectionString: string
    credentials: Record<string, string>
  }> {
    // Generate credentials
    const dbUser = `u_${instanceId.slice(0, 8)}`
    const dbPassword =
      crypto.randomUUID().replace(/-/g, '') +
      crypto.randomUUID().replace(/-/g, '').slice(0, 16)
    const dbName = `db_${instanceId.slice(0, 8)}`

    // In production, this would:
    // 1. Find available PostgreSQL nodes with capacity
    // 2. Initialize PostgreSQL instance with pg_basebackup
    // 3. Configure pg_hba.conf and postgresql.conf
    // 4. Set up PgBouncer for connection pooling
    // 5. Configure streaming replication for replicas
    // 6. Set up automatic failover with Patroni

    const directHost = `pg-${instanceId}.dws.jejunetwork.org`
    const poolerHost = `pgpool-${instanceId}.dws.jejunetwork.org`
    const port = 5432
    const poolerPort = 6432

    // Connection string for direct access
    const directConnectionString = `postgresql://${dbUser}:${dbPassword}@${directHost}:${port}/${dbName}?sslmode=require`

    // Connection string for pooled access (recommended)
    const pooledConnectionString = `postgresql://${dbUser}:${dbPassword}@${poolerHost}:${poolerPort}/${dbName}?sslmode=require`

    const job = this.jobs.get(instanceId)
    if (job) {
      job.status = 'completed'
      job.completedAt = Date.now()
    }

    console.log(`[DatabaseProvisioner] PostgreSQL ${instanceId} provisioned`)

    return {
      connectionString: pooledConnectionString,
      credentials: {
        host: directHost,
        poolerHost,
        port: String(port),
        poolerPort: String(poolerPort),
        database: dbName,
        user: dbUser,
        password: dbPassword,
        sslmode: 'require',
        directUrl: directConnectionString,
        pooledUrl: pooledConnectionString,
      },
    }
  }

  async deprovision(instanceId: string): Promise<void> {
    console.log(`[DatabaseProvisioner] Deprovisioning ${instanceId}`)
    this.jobs.delete(instanceId)
  }

  getJob(instanceId: string): ProvisioningJob | undefined {
    return this.jobs.get(instanceId)
  }
}

// ============================================================================
// Backup Manager
// ============================================================================

interface BackupJob {
  backupId: string
  instanceId: string
  engine: DatabaseEngine
  status: BackupStatus
  startedAt: number
  completedAt: number | null
  sizeBytes: number
  storageCid: string | null
  error: string | null
}

class BackupManager {
  private jobs = new Map<string, BackupJob>()
  private backend: BackendManager

  constructor(backend: BackendManager) {
    this.backend = backend
  }

  async createBackup(
    backupId: string,
    instanceId: string,
    engine: DatabaseEngine,
    connectionInfo: Record<string, string>,
  ): Promise<void> {
    const job: BackupJob = {
      backupId,
      instanceId,
      engine,
      status: 'in_progress',
      startedAt: Date.now(),
      completedAt: null,
      sizeBytes: 0,
      storageCid: null,
      error: null,
    }
    this.jobs.set(backupId, job)

    console.log(`[BackupManager] Starting backup ${backupId} for ${instanceId}`)

    try {
      let backupData: Buffer

      if (engine === 'sqlit') {
        backupData = await this.backupSQLit(connectionInfo)
      } else if (engine === 'postgresql') {
        backupData = await this.backupPostgreSQL(connectionInfo)
      } else {
        throw new Error(`Unsupported engine: ${engine}`)
      }

      // Upload to IPFS
      const uploadResult = await this.backend.upload(backupData, {
        filename: `backup-${backupId}.sql.gz`,
        permanent: true,
      })

      job.status = 'completed'
      job.completedAt = Date.now()
      job.sizeBytes = backupData.length
      job.storageCid = uploadResult.cid

      console.log(
        `[BackupManager] Backup ${backupId} completed, CID: ${uploadResult.cid}`,
      )
    } catch (error) {
      job.status = 'failed'
      job.error = error instanceof Error ? error.message : String(error)
      console.error(`[BackupManager] Backup ${backupId} failed:`, error)
    }
  }

  private async backupSQLit(
    connectionInfo: Record<string, string>,
  ): Promise<Buffer> {
    const endpoint = connectionInfo.endpoint
    const authToken = connectionInfo.authToken

    // Call SQLit backup API
    const response = await fetch(`${endpoint}/backup`, {
      method: 'POST',
      headers: {
        Authorization: `Bearer ${authToken}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ format: 'sqlite' }),
    })

    if (!response.ok) {
      // Fallback: dump via SQL queries if backup API not available
      console.warn(
        `[BackupManager] SQLit backup API unavailable, using SQL dump fallback`,
      )
      const dumpResponse = await fetch(`${endpoint}/query`, {
        method: 'POST',
        headers: {
          Authorization: `Bearer ${authToken}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          sql: `.dump`,
        }),
      })

      if (!dumpResponse.ok) {
        throw new Error(`SQLit backup failed: ${dumpResponse.status}`)
      }

      const dumpData = await dumpResponse.text()
      const compressed = Bun.gzipSync(Buffer.from(dumpData))
      return Buffer.from(compressed)
    }

    const backupData = await response.arrayBuffer()
    const compressed = Bun.gzipSync(Buffer.from(backupData))
    return Buffer.from(compressed)
  }

  private async backupPostgreSQL(
    connectionInfo: Record<string, string>,
  ): Promise<Buffer> {
    const host = connectionInfo.host
    const port = connectionInfo.port ?? '5432'
    const database = connectionInfo.database
    const user = connectionInfo.user
    const password = connectionInfo.password

    // Use pg_dump via subprocess
    const proc = Bun.spawn(
      [
        'pg_dump',
        '--format=custom',
        '--compress=9',
        '--no-password',
        `--host=${host}`,
        `--port=${port}`,
        `--username=${user}`,
        `--dbname=${database}`,
      ],
      {
        env: {
          ...process.env,
          PGPASSWORD: password,
        },
        stdout: 'pipe',
        stderr: 'pipe',
      },
    )

    const chunks: Uint8Array[] = []
    const reader = proc.stdout.getReader()

    while (true) {
      const { done, value } = await reader.read()
      if (done) break
      chunks.push(value)
    }

    const exitCode = await proc.exited
    if (exitCode !== 0) {
      const stderrReader = proc.stderr.getReader()
      const stderrChunks: Uint8Array[] = []
      while (true) {
        const { done, value } = await stderrReader.read()
        if (done) break
        stderrChunks.push(value)
      }
      const stderr = Buffer.concat(stderrChunks).toString()
      throw new Error(`pg_dump failed (exit ${exitCode}): ${stderr}`)
    }

    return Buffer.concat(chunks)
  }

  async restoreBackup(
    backupId: string,
    instanceId: string,
    engine: DatabaseEngine,
    connectionInfo: Record<string, string>,
    storageCid: string,
  ): Promise<void> {
    console.log(`[BackupManager] Restoring backup ${backupId} to ${instanceId}`)

    // Download backup from IPFS
    const downloadResult = await this.backend.download(storageCid)
    const backupData = downloadResult.content

    if (engine === 'sqlit') {
      await this.restoreSQLit(connectionInfo, backupData)
    } else if (engine === 'postgresql') {
      await this.restorePostgreSQL(connectionInfo, backupData)
    } else {
      throw new Error(`Unsupported engine: ${engine}`)
    }

    console.log(`[BackupManager] Restore completed for ${instanceId}`)
  }

  private async restoreSQLit(
    connectionInfo: Record<string, string>,
    data: Buffer,
  ): Promise<void> {
    const endpoint = connectionInfo.endpoint
    const authToken = connectionInfo.authToken

    // Convert Buffer to ArrayBuffer for Bun APIs
    const dataArray = new ArrayBuffer(data.length)
    const view = new Uint8Array(dataArray)
    for (let i = 0; i < data.length; i++) {
      view[i] = data[i]
    }

    // Decompress if gzipped
    let bodyData: ArrayBuffer
    try {
      const decompressed = Bun.gunzipSync(view)
      // Bun.gunzipSync always returns a fresh ArrayBuffer, not SharedArrayBuffer
      bodyData = (decompressed.buffer as ArrayBuffer).slice(
        decompressed.byteOffset,
        decompressed.byteOffset + decompressed.byteLength,
      )
    } catch {
      bodyData = dataArray
    }

    console.log(
      `[BackupManager] Restoring ${bodyData.byteLength} bytes to SQLit at ${endpoint}`,
    )

    // Send restore request to SQLit
    const response = await fetch(`${endpoint}/restore`, {
      method: 'POST',
      headers: {
        Authorization: `Bearer ${authToken}`,
        'Content-Type': 'application/octet-stream',
      },
      body: bodyData,
    })

    if (!response.ok) {
      throw new Error(
        `SQLit restore failed: ${response.status} ${await response.text()}`,
      )
    }
  }

  private async restorePostgreSQL(
    connectionInfo: Record<string, string>,
    data: Buffer,
  ): Promise<void> {
    const host = connectionInfo.host
    const port = connectionInfo.port ?? '5432'
    const database = connectionInfo.database
    const user = connectionInfo.user
    const password = connectionInfo.password

    console.log(
      `[BackupManager] Restoring ${data.length} bytes to PostgreSQL at ${host}:${port}/${database}`,
    )

    // Write backup to temp file for pg_restore
    const tempFile = `/tmp/dws-restore-${Date.now()}.dump`
    await Bun.write(tempFile, data)

    try {
      // Use pg_restore via subprocess
      const proc = Bun.spawn(
        [
          'pg_restore',
          '--format=custom',
          '--clean',
          '--if-exists',
          '--no-password',
          `--host=${host}`,
          `--port=${port}`,
          `--username=${user}`,
          `--dbname=${database}`,
          tempFile,
        ],
        {
          env: {
            ...process.env,
            PGPASSWORD: password,
          },
          stdout: 'pipe',
          stderr: 'pipe',
        },
      )

      const exitCode = await proc.exited
      if (exitCode !== 0) {
        const stderrReader = proc.stderr.getReader()
        const stderrChunks: Uint8Array[] = []
        while (true) {
          const { done, value } = await stderrReader.read()
          if (done) break
          stderrChunks.push(value)
        }
        const stderr = Buffer.concat(stderrChunks).toString()
        // pg_restore returns non-zero even for warnings, so only error on actual failures
        if (!stderr.includes('errors ignored')) {
          console.warn(`[BackupManager] pg_restore warnings: ${stderr}`)
        }
      }
    } finally {
      // Clean up temp file
      const fs = await import('node:fs/promises')
      await fs.unlink(tempFile).catch(() => {})
    }
  }

  getJob(backupId: string): BackupJob | undefined {
    return this.jobs.get(backupId)
  }
}

// ============================================================================
// Managed Database Service
// ============================================================================

export class ManagedDatabaseService {
  private instances = new Map<string, DatabaseInstance>()
  private connections = new Map<string, PostgresConnection | SQLitConnection>()
  private credentials = new Map<string, Record<string, string>>()
  private poolManager: ConnectionPoolManager
  private provisioner: DatabaseProvisioner
  private backupManager: BackupManager
  private backend: BackendManager

  // Contract interaction
  private publicClient: ReturnType<typeof createPublicClient>
  private walletClient: ReturnType<typeof createWalletClient> | null = null
  private registryAddress: Address

  constructor(
    backend: BackendManager,
    config: { rpcUrl: string; registryAddress: Address; privateKey?: Hex },
  ) {
    this.backend = backend
    this.poolManager = new ConnectionPoolManager()
    this.provisioner = new DatabaseProvisioner()
    this.backupManager = new BackupManager(backend)

    this.registryAddress = config.registryAddress

    const chain = {
      ...foundry,
      rpcUrls: { default: { http: [config.rpcUrl] } },
    }
    this.publicClient = createPublicClient({
      chain,
      transport: http(config.rpcUrl),
    })

    if (config.privateKey) {
      const account = privateKeyToAccount(config.privateKey)
      this.walletClient = createWalletClient({
        account,
        chain,
        transport: http(config.rpcUrl),
      })
    }
  }

  /** Get contract configuration (for future on-chain registration) */
  getContractConfig() {
    return {
      backend: this.backend,
      publicClient: this.publicClient,
      walletClient: this.walletClient,
      registryAddress: this.registryAddress,
    }
  }

  // =========================================================================
  // Instance Lifecycle
  // =========================================================================

  async createDatabase(
    owner: Address,
    params: z.infer<typeof CreateDatabaseSchema>,
  ): Promise<DatabaseInstance> {
    const instanceId = keccak256(
      stringToBytes(`${owner}-${params.name}-${Date.now()}`),
    ) as Hex

    const defaultConfig: DatabaseConfig = {
      vcpus: params.config?.vcpus ?? 1,
      memoryMb: params.config?.memoryMb ?? 1024,
      storageMb: params.config?.storageMb ?? 10240,
      readReplicas: params.config?.readReplicas ?? 0,
      maxConnections: params.config?.maxConnections ?? 100,
      connectionPoolSize: params.config?.connectionPoolSize ?? 25,
      backupRetentionDays: params.config?.backupRetentionDays ?? 7,
      pointInTimeRecovery: params.config?.pointInTimeRecovery ?? false,
      encryptionAtRest: true,
      encryptionInTransit: true,
      publicAccess: params.config?.publicAccess ?? false,
      replicationFactor: params.config?.replicationFactor ?? 3,
      consistencyMode: params.config?.consistencyMode ?? 'strong',
    }

    const instance: DatabaseInstance = {
      instanceId,
      owner,
      engine: params.engine as DatabaseEngine,
      name: params.name,
      status: 'provisioning',
      config: defaultConfig,
      connectionString: '',
      createdAt: Date.now(),
      updatedAt: Date.now(),
      lastBackupAt: 0,
      planId: params.planId as Hex,
      region: params.region,
    }

    this.instances.set(instanceId, instance)

    // Provision asynchronously
    this.provisionInstance(instance).catch((error) => {
      console.error(
        `[ManagedDatabaseService] Provisioning failed for ${instanceId}:`,
        error,
      )
      instance.status = 'failed'
    })

    return instance
  }

  private async provisionInstance(instance: DatabaseInstance): Promise<void> {
    console.log(
      `[ManagedDatabaseService] Provisioning ${instance.name} (${instance.engine})`,
    )

    const result = await this.provisioner.provision(
      instance.instanceId,
      instance.engine,
      instance.config,
      instance.region,
    )

    instance.connectionString = result.connectionString
    instance.status = 'running'
    instance.updatedAt = Date.now()

    this.credentials.set(instance.instanceId, result.credentials)

    // Set up connection pooling
    if (instance.engine === 'postgresql') {
      this.poolManager.configure(instance.instanceId, {
        mode: 'transaction',
        defaultPoolSize: instance.config.connectionPoolSize,
        maxClientConnections: instance.config.maxConnections,
        reservePoolSize: 5,
        queryTimeout: 30000,
        idleTimeout: 300000,
      })

      const creds = result.credentials
      this.connections.set(instance.instanceId, {
        host: creds.host,
        port: parseInt(creds.port, 10),
        database: creds.database,
        user: creds.user,
        password: creds.password,
        ssl: creds.sslmode === 'require',
        poolerEndpoint: creds.pooledUrl,
        directEndpoint: creds.directUrl,
      } as PostgresConnection)
    } else if (instance.engine === 'sqlit') {
      const creds = result.credentials
      this.connections.set(instance.instanceId, {
        endpoint: creds.endpoint,
        authToken: creds.authToken,
        syncUrl: creds.syncUrl,
        nodes: creds.nodes.split(','),
      } as SQLitConnection)
    }

    console.log(`[ManagedDatabaseService] ${instance.name} is now running`)
  }

  async updateDatabase(
    instanceId: string,
    owner: Address,
    updates: z.infer<typeof UpdateDatabaseSchema>,
  ): Promise<DatabaseInstance> {
    const instance = this.instances.get(instanceId)
    if (!instance) throw new Error(`Instance not found: ${instanceId}`)
    if (instance.owner !== owner) throw new Error('Not authorized')
    if (instance.status !== 'running') throw new Error('Instance not running')

    instance.status = 'scaling'
    instance.updatedAt = Date.now()

    // Apply updates
    if (updates.vcpus !== undefined) instance.config.vcpus = updates.vcpus
    if (updates.memoryMb !== undefined)
      instance.config.memoryMb = updates.memoryMb
    if (updates.storageMb !== undefined)
      instance.config.storageMb = updates.storageMb
    if (updates.readReplicas !== undefined)
      instance.config.readReplicas = updates.readReplicas
    if (updates.maxConnections !== undefined)
      instance.config.maxConnections = updates.maxConnections
    if (updates.connectionPoolSize !== undefined)
      instance.config.connectionPoolSize = updates.connectionPoolSize

    // Reconfigure pool
    if (
      instance.engine === 'postgresql' &&
      updates.connectionPoolSize !== undefined
    ) {
      this.poolManager.configure(instanceId, {
        mode: 'transaction',
        defaultPoolSize: instance.config.connectionPoolSize,
        maxClientConnections: instance.config.maxConnections,
        reservePoolSize: 5,
        queryTimeout: 30000,
        idleTimeout: 300000,
      })
    }

    // Simulate scaling delay
    await new Promise((r) => setTimeout(r, 2000))

    instance.status = 'running'
    instance.updatedAt = Date.now()

    return instance
  }

  async stopDatabase(instanceId: string, owner: Address): Promise<void> {
    const instance = this.instances.get(instanceId)
    if (!instance) throw new Error(`Instance not found: ${instanceId}`)
    if (instance.owner !== owner) throw new Error('Not authorized')

    instance.status = 'stopped'
    instance.updatedAt = Date.now()

    this.poolManager.destroy(instanceId)
  }

  async startDatabase(instanceId: string, owner: Address): Promise<void> {
    const instance = this.instances.get(instanceId)
    if (!instance) throw new Error(`Instance not found: ${instanceId}`)
    if (instance.owner !== owner) throw new Error('Not authorized')
    if (instance.status !== 'stopped') throw new Error('Instance not stopped')

    await this.provisionInstance(instance)
  }

  async deleteDatabase(instanceId: string, owner: Address): Promise<void> {
    const instance = this.instances.get(instanceId)
    if (!instance) throw new Error(`Instance not found: ${instanceId}`)
    if (instance.owner !== owner) throw new Error('Not authorized')

    instance.status = 'terminated'
    instance.updatedAt = Date.now()

    await this.provisioner.deprovision(instanceId)
    this.poolManager.destroy(instanceId)
    this.connections.delete(instanceId)
    this.credentials.delete(instanceId)

    // Keep instance record for audit
  }

  // =========================================================================
  // Connections
  // =========================================================================

  async getConnection(
    instanceId: string,
    owner: Address,
  ): Promise<PostgresConnection | SQLitConnection> {
    const instance = this.instances.get(instanceId)
    if (!instance) throw new Error(`Instance not found: ${instanceId}`)
    if (instance.owner !== owner) throw new Error('Not authorized')
    if (instance.status !== 'running') throw new Error('Instance not running')

    const conn = this.connections.get(instanceId)
    if (!conn) throw new Error('Connection info not available')

    return conn
  }

  async acquirePooledConnection(
    instanceId: string,
    clientId: string,
  ): Promise<string> {
    const instance = this.instances.get(instanceId)
    if (!instance || instance.engine !== 'postgresql') {
      throw new Error('Pooling only available for PostgreSQL')
    }

    const conn = await this.poolManager.acquire(instanceId, clientId)
    return conn.id
  }

  releasePooledConnection(instanceId: string, connectionId: string): void {
    this.poolManager.release(instanceId, connectionId)
  }

  getPoolStats(instanceId: string): {
    total: number
    inUse: number
    available: number
    waiting: number
  } {
    return this.poolManager.getStats(instanceId)
  }

  // =========================================================================
  // Backups
  // =========================================================================

  async createBackup(instanceId: string, owner: Address): Promise<Backup> {
    const instance = this.instances.get(instanceId)
    if (!instance) throw new Error(`Instance not found: ${instanceId}`)
    if (instance.owner !== owner) throw new Error('Not authorized')
    if (instance.status !== 'running') throw new Error('Instance not running')

    const backupId = keccak256(
      stringToBytes(`${instanceId}-${Date.now()}`),
    ) as Hex
    const creds = this.credentials.get(instanceId)
    if (!creds) throw new Error('Credentials not available')

    const backup: Backup = {
      backupId,
      instanceId: instance.instanceId,
      status: 'in_progress',
      createdAt: Date.now(),
      completedAt: 0,
      sizeBytes: 0,
      storageCid: '',
      expiresAt:
        Date.now() + instance.config.backupRetentionDays * 24 * 60 * 60 * 1000,
      isAutomatic: false,
    }

    instance.status = 'backing_up'
    instance.updatedAt = Date.now()

    // Run backup asynchronously
    this.backupManager
      .createBackup(backupId, instanceId, instance.engine, creds)
      .then(() => {
        const job = this.backupManager.getJob(backupId)
        if (job) {
          backup.status = job.status
          backup.completedAt = job.completedAt ?? 0
          backup.sizeBytes = job.sizeBytes
          backup.storageCid = job.storageCid ?? ''
        }
        instance.status = 'running'
        instance.lastBackupAt = Date.now()
        instance.updatedAt = Date.now()
      })

    return backup
  }

  async restoreBackup(
    instanceId: string,
    backupId: string,
    owner: Address,
  ): Promise<void> {
    const instance = this.instances.get(instanceId)
    if (!instance) throw new Error(`Instance not found: ${instanceId}`)
    if (instance.owner !== owner) throw new Error('Not authorized')

    const creds = this.credentials.get(instanceId)
    if (!creds) throw new Error('Credentials not available')

    // Get backup job to retrieve storage CID
    const backupJob = this.backupManager.getJob(backupId)
    if (!backupJob) throw new Error(`Backup not found: ${backupId}`)
    if (backupJob.status !== 'completed')
      throw new Error(`Backup not ready: ${backupJob.status}`)
    if (!backupJob.storageCid)
      throw new Error('Backup storage CID not available')

    instance.status = 'restoring'
    instance.updatedAt = Date.now()

    await this.backupManager.restoreBackup(
      backupId,
      instanceId,
      instance.engine,
      creds,
      backupJob.storageCid,
    )

    instance.status = 'running'
    instance.updatedAt = Date.now()
  }

  // =========================================================================
  // Replicas (PostgreSQL)
  // =========================================================================

  async createReplica(
    instanceId: string,
    owner: Address,
    region: string,
  ): Promise<Replica> {
    const instance = this.instances.get(instanceId)
    if (!instance) throw new Error(`Instance not found: ${instanceId}`)
    if (instance.owner !== owner) throw new Error('Not authorized')
    if (instance.engine !== 'postgresql')
      throw new Error('Replicas only available for PostgreSQL')
    if (instance.status !== 'running') throw new Error('Instance not running')

    const replicaId = keccak256(
      stringToBytes(`${instanceId}-replica-${region}-${Date.now()}`),
    ) as Hex

    const replica: Replica = {
      replicaId,
      instanceId: instance.instanceId,
      role: 'read_replica',
      endpoint: `pg-replica-${replicaId.slice(0, 8)}.dws.jejunetwork.org:5432`,
      region,
      lagMs: 0,
      healthy: true,
    }

    console.log(
      `[ManagedDatabaseService] Created replica ${replicaId} in ${region}`,
    )

    return replica
  }

  async promoteReplica(replicaId: string, _owner: Address): Promise<void> {
    console.log(`[ManagedDatabaseService] Promoting replica ${replicaId}`)
    // In production: initiate failover with Patroni
  }

  // =========================================================================
  // Queries
  // =========================================================================

  getInstance(instanceId: string): DatabaseInstance | undefined {
    return this.instances.get(instanceId)
  }

  getInstancesByOwner(owner: Address): DatabaseInstance[] {
    return Array.from(this.instances.values()).filter((i) => i.owner === owner)
  }

  listInstances(): DatabaseInstance[] {
    return Array.from(this.instances.values())
  }

  getCredentials(instanceId: string, owner: Address): Record<string, string> {
    const instance = this.instances.get(instanceId)
    if (!instance) throw new Error(`Instance not found: ${instanceId}`)
    if (instance.owner !== owner) throw new Error('Not authorized')

    const creds = this.credentials.get(instanceId)
    if (!creds) throw new Error('Credentials not available')

    return creds
  }
}

// ============================================================================
// Factory
// ============================================================================

let managedDatabaseService: ManagedDatabaseService | null = null

export function getManagedDatabaseService(
  backend: BackendManager,
): ManagedDatabaseService {
  if (!managedDatabaseService) {
    const network = getCurrentNetwork()
    const rpcUrl = getRpcUrl(network)
    const registryAddress = (tryGetContract(
      'dws',
      'managedDatabaseRegistry',
      network,
    ) || '0x0000000000000000000000000000000000000000') as Address
    // Private key is a secret - keep as env var
    const privateKey =
      typeof process !== 'undefined'
        ? (process.env.DWS_OPERATOR_KEY as Hex | undefined)
        : undefined

    managedDatabaseService = new ManagedDatabaseService(backend, {
      rpcUrl,
      registryAddress,
      privateKey,
    })
  }
  return managedDatabaseService
}
